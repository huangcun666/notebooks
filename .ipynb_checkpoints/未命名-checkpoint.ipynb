{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file= open(\"mnist_train_100.csv\", 'r')\n",
    "data_list= data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8b791f6ac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "all_values=data_list[0].split(',') \n",
    "image_array=numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array,cmap='Greys',interpolation='None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.208      0.62729412 0.99223529 0.62729412 0.20411765\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.19635294 0.934\n",
      " 0.98835294 0.98835294 0.98835294 0.93011765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.21964706 0.89129412 0.99223529 0.98835294 0.93788235\n",
      " 0.91458824 0.98835294 0.23129412 0.03329412 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.04882353 0.24294118 0.87964706\n",
      " 0.98835294 0.99223529 0.98835294 0.79423529 0.33611765 0.98835294\n",
      " 0.99223529 0.48364706 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.64282353 0.98835294 0.98835294 0.98835294 0.99223529\n",
      " 0.98835294 0.98835294 0.38270588 0.74376471 0.99223529 0.65835294\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.208      0.934\n",
      " 0.99223529 0.99223529 0.74764706 0.45258824 0.99223529 0.89517647\n",
      " 0.19247059 0.31670588 1.         0.66223529 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.19635294 0.934      0.98835294 0.98835294 0.70494118\n",
      " 0.05658824 0.30117647 0.47976471 0.09152941 0.01       0.01\n",
      " 0.99223529 0.95341176 0.20411765 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.15752941 0.65058824\n",
      " 0.99223529 0.91458824 0.81752941 0.33611765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.99223529 0.98835294\n",
      " 0.65058824 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.03717647 0.70105882 0.98835294 0.94176471 0.28564706\n",
      " 0.08376471 0.11870588 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.99223529 0.98835294 0.76705882 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.23129412\n",
      " 0.98835294 0.98835294 0.25458824 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.99223529 0.98835294 0.76705882 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.77870588 0.99223529 0.74764706\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       1.         0.99223529\n",
      " 0.77094118 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.30505882 0.96505882 0.98835294 0.44482353 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.99223529 0.98835294 0.58458824 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.34       0.98835294\n",
      " 0.90294118 0.10705882 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.03717647 0.53411765\n",
      " 0.99223529 0.73211765 0.05658824 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.34       0.98835294 0.87576471 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.03717647 0.51858824 0.98835294 0.88352941 0.28564706\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.34       0.98835294 0.57294118 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.19635294 0.65058824\n",
      " 0.98835294 0.68164706 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.34388235 0.99223529\n",
      " 0.88352941 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.45258824 0.934      0.99223529 0.63894118 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.34       0.98835294 0.97670588 0.57682353\n",
      " 0.19635294 0.12258824 0.34       0.70105882 0.88352941 0.99223529\n",
      " 0.87576471 0.65835294 0.22741176 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.34       0.98835294 0.98835294 0.98835294 0.89905882 0.84470588\n",
      " 0.98835294 0.98835294 0.98835294 0.77094118 0.51470588 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.11870588 0.78258824\n",
      " 0.98835294 0.98835294 0.99223529 0.98835294 0.98835294 0.91458824\n",
      " 0.57294118 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.10705882 0.50694118 0.98835294\n",
      " 0.99223529 0.98835294 0.55741176 0.15364706 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "scaled_input=(numpy.asfarray(all_values[1:])/255*0.99)+0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onodes=10\n",
    "targerts=numpy.zeros(onodes)+0.01\n",
    "targerts[int(all_values[0])]=0.99\n",
    "print(targerts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    def __init__(self,inputnodes,hiddennodes,outputnodes,learningrate):\n",
    "        self.inodes=inputnodes\n",
    "        self.hnodes=hiddennodes\n",
    "        self.onodes=outputnodes\n",
    "        self.lr=learningrate\n",
    "#         self.wih=(numpy.random.rand(self.hnodes,self.inodes)-0.5)\n",
    "#         self.who=(numpy.random.rand(self.onodes,self.hnodes)-0.5)\n",
    "        self.wih=numpy.random.normal(0.0,pow(self.hnodes,-0.5),(self.hnodes,self.inodes))\n",
    "        self.who=numpy.random.normal(0.0,pow(self.onodes,-0.5),(self.onodes,self.hnodes))\n",
    "        self.activation_function=lambda x: scipy.special.expit(x)\n",
    "    def train(self,inputs_list,targets_list):\n",
    "        inputs=numpy.array(inputs_list,ndmin=2).T\n",
    "        targets=numpy.array(targets_list,ndmin=2).T\n",
    "        hidden_inputs=numpy.dot(self.wih,inputs)\n",
    "        \n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs=numpy.dot(self.who,hidden_outputs)\n",
    "        \n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors=targets-final_outputs\n",
    "        hidden_errors=numpy.dot(self.who.T,output_errors)\n",
    "        self.who += self.lr * numpy.dot((output_errors *\n",
    "            final_outputs * (1.0 - final_outputs)),\n",
    "            numpy.transpose(hidden_outputs))\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors *\n",
    "            hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "    def query(self,inputs_list):\n",
    "        inputs=numpy.array(inputs_list,ndmin=2).T\n",
    "        hidden_inputs=numpy.dot(self.wih,inputs)\n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        final_inputs=numpy.dot(self.who,hidden_outputs)\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,\n",
    "learning_rate)\n",
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "# train the neural network\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "s=numpy.random.normal(0.0,3,1000)\n",
    "plt.hist(s,bins=100,normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
